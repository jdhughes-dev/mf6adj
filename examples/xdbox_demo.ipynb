{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e35d104a-652b-4167-86c0-c8f9eaf0b8d3",
   "metadata": {},
   "source": [
    "# mf6adj box example\n",
    "\n",
    "In this notebook, we will test MF6ADJ using a simple box problem and compare the result with analytical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374d723-48a8-4e57-b0a4-29ad861c9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib as pl\n",
    "import platform\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import flopy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyemu\n",
    "\n",
    "try:\n",
    "    import mf6adj\n",
    "except ImportError:\n",
    "    sys.path.insert(0, str(pl.Path(\"../\").resolve()))\n",
    "    import mf6adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63992ead-4e38-4465-a5af-523f9d0718d7",
   "metadata": {},
   "source": [
    "First we need to get the platform-specific binaries. We have some strict control over these and they are stored at the root level in the repo in the bin dir. Let's workout what path we should be using and the binary names we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12516e-c8a9-46d2-916a-73d4b199e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = pl.Path(os.environ.get(\"CONDA_PREFIX\", None))\n",
    "assert env_path is not None, \"Notebook must be run from the mf6adj Conda environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53aca5-a1e2-4a12-a08b-2806af766de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"bin\"\n",
    "exe_ext = \"\"\n",
    "if \"linux\" in platform.platform().lower():\n",
    "    lib_ext = \".so\"\n",
    "elif \"darwin\" in platform.platform().lower() or \"macos\" in platform.platform().lower():\n",
    "    lib_ext = \".dylib\"\n",
    "else:\n",
    "    bin_path = \"Scripts\"\n",
    "    lib_ext = \".dll\"\n",
    "    exe_ext = \".exe\"\n",
    "lib_name = env_path / f\"{bin_path}/libmf6{lib_ext}\"\n",
    "mf6_bin = env_path / f\"{bin_path}/mf6{exe_ext}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cc24e-8006-452d-80a1-bdd8c870e196",
   "metadata": {},
   "source": [
    "Now let's get the model files we will be using - they are stored in the autotest directory (here names as: xd_box_chd_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e073f7-b731-422c-8732-4a6159591582",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ws = os.path.join(\"xd_box_chd_ana\")\n",
    "assert os.path.exists(org_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09d31e-470c-48df-8596-4cc081d371b9",
   "metadata": {},
   "source": [
    "setup a local copy of the model files. Also copy in the binaries we need for later...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d5c70-59c3-45ad-abdf-64bf45731d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = \"xd_box_chd_ana_working\"\n",
    "if os.path.exists(ws):\n",
    "    shutil.rmtree(ws)\n",
    "shutil.copytree(org_ws, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd858ba-afb4-4394-afdf-8a2e59ec5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=ws)\n",
    "m = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20565701-4f31-4e1a-bf93-38c92768db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = m.dis.idomain.array[0, :, :].astype(float)\n",
    "ib[ib > 0] = np.nan\n",
    "ib_cmap = plt.get_cmap(\"Greys_r\")\n",
    "ib_cmap.set_bad(alpha=0.0)\n",
    "\n",
    "\n",
    "def plot_model(arr, units=None):\n",
    "    arr[~np.isnan(ib)] = np.nan\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    cb = ax.imshow(arr, cmap=\"plasma\")\n",
    "    plt.colorbar(cb, ax=ax, label=units)\n",
    "    plt.imshow(ib, cmap=ib_cmap)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044d45b-6c41-4e46-ae5e-652f9c8c352d",
   "metadata": {},
   "source": [
    "Run the existing model in our local workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8852e71-90d4-48bc-9388-6b79ef43faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf6_bin)\n",
    "print(ws)\n",
    "print(os.listdir(ws))\n",
    "pyemu.os_utils.run(mf6_bin.name, cwd=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cf5a8-0fe0-4fac-bf89-3aac9f2772db",
   "metadata": {},
   "source": [
    "Now plot some heads..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7dc9a4-898f-46b5-8be9-c5d79d3f8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hds = flopy.utils.HeadFile(os.path.join(ws, \"xdbox.hds\"))\n",
    "final_arr = hds.get_data()\n",
    "fig, ax = plot_model(final_arr[0, :, :], units=\"meters\")\n",
    "ax.set_title(\"layer 1 final heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500b0b5-b527-4b96-a39e-c4141eb162db",
   "metadata": {},
   "source": [
    "The main requirement to use Mf6Adj is an input file that describes the performance measures. Luckily this file has a nice modern format like other MF6 input files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef7b14-89cb-476a-983d-a85fd39c268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_fname = \"xdbox.dat\"\n",
    "fpm = open(os.path.join(ws, pm_fname), \"w\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "125d5a01-d288-49f4-b96c-edfa06ca0c5b",
   "metadata": {},
   "source": [
    "Here we use a performance measure defined as a single simulated head at one place for one simulation time. For such performance measure, an analytical solution exists, soit can be used for comparison. Lets make one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef8e83-bbdb-460f-805b-61afae6c34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, r, c = 1, 41, 21  # the layer row and column\n",
    "sp, ts = 1, 1  # stress period and time step\n",
    "pm_name = \"pm_single\"\n",
    "fpm.write(\"begin performance_measure {0}\\n\".format(pm_name))\n",
    "fpm.write(\"{0} {1} {2} {3} {4} head direct 1.0 -1e30\\n\".format(sp, ts, l, r, c))\n",
    "fpm.write(\"end performance_measure\\n\\n\")\n",
    "fpm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8367c7e-a5fe-4c42-bd11-377b2cede2e5",
   "metadata": {},
   "source": [
    "Ok, now we should be ready to go...the adjoint solution process requires running the model forward once and then solving for the adjoint state, which uses the forward solution components (i.e. the conductance matrix, the RHS, heads, saturation,etc). The adjoint state solution has two important characteristics: its a linear (independent of the forward model's linearity) and it solves backward in time, starting with the last stress period - WAT?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8887f18-5592-4467-abc1-daddb184fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = os.getcwd()\n",
    "os.chdir(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0164969-1be6-4248-9db7-994471e1d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_hdf5_name = \"forward.hdf5\"\n",
    "start = datetime.now()\n",
    "import mf6adj\n",
    "\n",
    "adj = mf6adj.Mf6Adj(pm_fname, lib_name, logging_level=\"INFO\")\n",
    "adj.solve_gwf(hdf5_name=forward_hdf5_name)  # solve the standard forward solution\n",
    "dfsum = adj.solve_adjoint()  # solve the adjoint state for each performance measure\n",
    "adj.finalize()  # release components\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "print(\"took:\", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f987f-4240-47cb-bacd-08073803a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7810ba03-33b3-464e-ab34-60d18c71dc15",
   "metadata": {},
   "source": [
    "Let's see what happened..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ebaea-6a26-4f7f-82a8-91b4be1ce249",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(ws) if f.endswith(\"hdf5\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199e25cf-f718-4b7b-b5c9-f6f887173d2f",
   "metadata": {},
   "source": [
    "MF6ADJ uses the widely available HDF5 format to store information - these files hold very low-level granular information about the adjoint solution. However the mf6adj.solve_adjoint() method also returns a higher-level summary of the adjoint solution. Let's look at it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fc852-8609-4630-a265-8cdaf5a27932",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c3c5e-56d2-49bd-a449-67d26ebe3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfsum.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699e8b3-cbc6-42ee-a478-6362a83a1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhw = dfsum[\"pm_single\"]\n",
    "dfhw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d3ebf-1a7c-40ef-893b-e0d86b909a62",
   "metadata": {},
   "source": [
    "those are the node-scale sensitivities to the sfr flux-based performance measure - some plots would be nice you say?! Well this is most easily done with the HDF5 file itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d30e55-b9c8-41fc-acca-7124c57fbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_pm_single_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "keys.sort()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d66ff6-c9d5-4948-8ef4-cb1f59ba90d3",
   "metadata": {},
   "source": [
    "The \"composite\" group has the sensitivities of the performance measure to the model inputs summed across all adjoint solutions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f73faf-d02e-4d56-84c4-cc512e605bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [i for i in grp.keys() if len(grp[i].shape) == 3]\n",
    "plot_keys\n",
    "grp[\"wel6_q\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c9d0e-c59b-4654-bb09-3d4f206a91a1",
   "metadata": {},
   "source": [
    "A simple routine to plot all these sensitivities...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f400c96-6f7f-45c8-9994-21f56771483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541ed7e-7bdc-4107-beda-ee7d4fb2c1c9",
   "metadata": {},
   "source": [
    "Defining the analytical solution (Lu and Vesselinov, WRR, 2015: doi:10.1002/2014WR016819) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfef1b7-07ce-471b-ad07-a2360559d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1, H2 = 1001.0, 1000.0  # Heads at both sides\n",
    "L1, L2 = 500.0, 400.0  # Domain size\n",
    "nlay, nrow, ncol = m.dis.nlay.data, m.dis.nrow.data, m.dis.ncol.data\n",
    "delrow, delcol = m.dis.delr.data[0], m.dis.delc.data[0]\n",
    "L1 = delrow * ncol\n",
    "L2 = delcol * nrow\n",
    "H = 1.0\n",
    "k = 10.0  # Hydraulic conductivity\n",
    "T = k * H  # Transmissivity\n",
    "D = L1 * L2\n",
    "\n",
    "\n",
    "def alpha(m):\n",
    "    return m * np.pi / L1\n",
    "\n",
    "\n",
    "def beta(n):\n",
    "    return n * np.pi / L2\n",
    "\n",
    "\n",
    "def omega_square(m, n):\n",
    "    return (alpha(m)) ** 2 + (beta(n)) ** 2\n",
    "\n",
    "\n",
    "def phi_s(x, y, xs, ys, M=5, N=5):\n",
    "    listofmindices = [item + 1 for item in range(M)]\n",
    "    Sum = 0.0\n",
    "    a = [0.5]\n",
    "    for i in [item + 1 for item in range(N)]:\n",
    "        a.append(1.0)\n",
    "    for n in range(N + 1):\n",
    "        for m in listofmindices:\n",
    "            Sum = Sum + a[n] * np.sin(alpha(m) * x) * np.cos(beta(n) * y) * np.sin(\n",
    "                alpha(m) * xs\n",
    "            ) * np.cos(beta(n) * ys) / omega_square(m, n)\n",
    "    Sum = (4 / (T * D)) * Sum\n",
    "    return Sum\n",
    "\n",
    "\n",
    "def get_analytical_adj_state(xs, ys, M, N):\n",
    "    list_adj_state = []\n",
    "    for j in range(nrow):\n",
    "        for i in range(ncol):\n",
    "            x = m.modelgrid.xcellcenters[j][i]\n",
    "            y = m.modelgrid.ycellcenters[j][i]\n",
    "            list_adj_state.append(phi_s(x, y, xs, ys, M=M, N=N))\n",
    "    array_adj_state = np.array(list_adj_state)\n",
    "    print(\"array_adj_state = \", array_adj_state)\n",
    "    filepath = os.path.join(ws, \"lamb_Analytical.txt\")\n",
    "    with open(filepath, \"w\") as file:\n",
    "        # with open('lamb_Analytical.txt', 'w') as file:\n",
    "        for value in array_adj_state:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    array_adj_state_2D = np.reshape(array_adj_state, (nrow, ncol))\n",
    "    return array_adj_state_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e97129-cf72-455c-a96b-b75e24c78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colorbar_contour(x, y, l_anal, l_num, vmin, vmax):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), constrained_layout=True)\n",
    "    ax = axes[0]\n",
    "    ax.set_title(\"Analytical\", fontsize=16)\n",
    "    cs = ax.contourf(x, y, l_anal, zorder=1, vmin=vmin, vmax=vmax)\n",
    "    ax.contour(cs, colors=\"k\", linewidths=1.0, linestyles=\"-\")\n",
    "    plt.colorbar(cs)\n",
    "    ax.set_xlabel(\"x (m)\", fontsize=14)\n",
    "    ax.set_ylabel(\"y (m)\", fontsize=14)\n",
    "    ax.text(-60.0, 420.0, \"a\", weight=\"bold\", fontsize=18)\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(\n",
    "        [0, 100, 200, 300, 400, 500], [\"0\", \"1000\", \"2000\", \"3000\", \"4000\", \"5000\"]\n",
    "    )\n",
    "    plt.yticks(\n",
    "        [0, 50, 100, 150, 200, 250, 300, 350, 400],\n",
    "        [\"0\", \"500\", \"1000\", \"1500\", \"2000\", \"2500\", \"3000\", \"3500\", \"4000\"],\n",
    "    )\n",
    "    ax = axes[1]\n",
    "    ax.set_title(\"MF6-ADJ\", fontsize=16)\n",
    "    cs = ax.contourf(x, y, l_num, zorder=1, vmin=vmin, vmax=vmax, levels=cs.levels)\n",
    "    ax.contour(cs, colors=\"k\", linewidths=1.0, linestyles=\"-\")\n",
    "    plt.colorbar(cs)\n",
    "    ax.set_xlabel(\"x (m)\", fontsize=14)\n",
    "    ax.set_ylabel(\"y (m)\", fontsize=14)\n",
    "    ax.text(-60.0, 420.0, \"b\", weight=\"bold\", fontsize=18)\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(\n",
    "        [0, 100, 200, 300, 400, 500], [\"0\", \"1000\", \"2000\", \"3000\", \"4000\", \"5000\"]\n",
    "    )\n",
    "    plt.yticks(\n",
    "        [0, 50, 100, 150, 200, 250, 300, 350, 400],\n",
    "        [\"0\", \"500\", \"1000\", \"1500\", \"2000\", \"2500\", \"3000\", \"3500\", \"4000\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef79ed6-bdd2-41ed-aa4b-4499da7ed1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M & N should be large enough to get convergence\n",
    "# of the analytical series solution (e.g., M=N=100)\n",
    "lam_anal = get_analytical_adj_state(100.0, 200.0, M=100, N=100)\n",
    "file_path = os.path.join(ws, \"lamb_Analytical.txt\")\n",
    "with open(file_path, \"r\") as file:\n",
    "    lamb_ana = [float(line.strip()) for line in file]\n",
    "    lamb_ana = np.array(lamb_ana)\n",
    "    lamb_ana_arr = lamb_ana\n",
    "    lamb_ana = np.reshape(lamb_ana, (nrow, ncol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32366009-6df9-4352-8f0d-a36b9dd2c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_adj = grp[\"wel6_q\"][:]\n",
    "x = np.linspace(0, L1, ncol)\n",
    "y = np.linspace(0, L2, nrow)\n",
    "x_center = [x[i] + delcol / 2.0 for i in range(len(x))]\n",
    "y_center = [y[i] + delrow / 2.0 for i in range(len(y))]\n",
    "y = y[::-1]\n",
    "y_center = y_center[::-1]\n",
    "vmin, vmax = lamb_ana.min(), lamb_ana.max()\n",
    "contour_intervals = np.arange(vmin, vmax, 0.003)\n",
    "plot_colorbar_contour(x, y, lamb_ana, lam_adj[0], vmin, vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9f745-36d0-4dc0-ad6a-76540d7a5b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf6adj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
