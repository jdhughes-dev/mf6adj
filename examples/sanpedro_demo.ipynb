{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc90795-fda6-4444-9ee3-94092d2d548e",
   "metadata": {},
   "source": [
    "# `MF6ADJ` demonstration using the San Pedro model\n",
    "\n",
    "In this notebook, we will see now `mf6adj` can be used with an MODFLOW-6 version of the famous San Pedro model of Leake and others (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c76ad2-37c7-43eb-9e9e-8bee668d15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib as pl\n",
    "import platform\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import flopy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec0f90-801e-47f2-b203-a5b6aba5b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import mf6adj\n",
    "except ImportError:\n",
    "    sys.path.insert(0, str(pl.Path(\"../\").resolve()))\n",
    "    import mf6adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701eb24-0fbd-4cb6-b12f-b4dc8bf18908",
   "metadata": {},
   "source": [
    "First we need to get the platform-specific binaries.  We have some strict control over these and they are stored at the root level in the repo in the `bin` dir.  Let's workout what path we should be using and the binary names we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a136c82-77f6-4b42-8554-329666381fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = pl.Path(os.environ.get(\"CONDA_PREFIX\", None))\n",
    "assert env_path is not None, \"Notebook must be run from the mf6adj Conda environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765da9ff-6d29-40d2-8f60-328695778ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"bin\"\n",
    "exe_ext = \"\"\n",
    "if \"linux\" in platform.platform().lower():\n",
    "    lib_ext = \".so\"\n",
    "elif \"darwin\" in platform.platform().lower() or \"macos\" in platform.platform().lower():\n",
    "    lib_ext = \".dylib\"\n",
    "else:\n",
    "    bin_path = \"Scripts\"\n",
    "    lib_ext = \".dll\"\n",
    "    exe_ext = \".exe\"\n",
    "lib_name = env_path / f\"{bin_path}/libmf6{lib_ext}\"\n",
    "mf6_bin = env_path / f\"{bin_path}/mf6{exe_ext}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293ef70-a3df-4517-b4f8-a8358ae21b1e",
   "metadata": {},
   "source": [
    "Now let's get the model files we will be using - they are stored in the autotest directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0ce01-6a15-4a0c-bbd2-edf24bb9bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ws = os.path.join(\"..\", \"autotest\", \"sanpedro\", \"mf6_transient_ghb\")\n",
    "assert os.path.exists(org_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c71ba8-e762-4df4-9f42-a2997cabf705",
   "metadata": {},
   "source": [
    "setup a local copy of the model files.  Also copy in the binaries we need for later...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd6674-86eb-4734-b80d-9d11a016461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = \"sanpedro\"\n",
    "if os.path.exists(ws):\n",
    "    shutil.rmtree(ws)\n",
    "shutil.copytree(org_ws, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62fe87-0221-43bd-be74-20c59d0b1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=ws)\n",
    "m = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34002a57-43da-4557-b46c-97ce1849fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = m.dis.idomain.array.astype(float)\n",
    "ib[ib > 0] = np.nan\n",
    "ib_cmap = plt.get_cmap(\"Greys_r\")\n",
    "ib_cmap.set_bad(alpha=0.0)\n",
    "\n",
    "\n",
    "def plot_model(k, arr, units=None):\n",
    "    arr[~np.isnan(ib[k, :, :])] = np.nan\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    cb = ax.imshow(arr, cmap=\"plasma\")\n",
    "    plt.colorbar(cb, ax=ax, label=units)\n",
    "    plt.imshow(ib[k, :, :], cmap=ib_cmap)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418ecbd-a885-4da6-9cad-a503aa360e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_model(4, m.dis.botm.array[4, :, :])\n",
    "_ = ax.set_title(\"botm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7d4ff-7ddb-426d-ad7b-5f5c63ac29b1",
   "metadata": {},
   "source": [
    "Run the existing model in our local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336aa2a-512c-4f5a-81e5-92f34f8be356",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(mf6_bin.name, cwd=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de008c-d873-47a0-8983-7747c65fe231",
   "metadata": {},
   "source": [
    "Now plot some heads..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d391c-75e5-40c6-91c5-8eed664fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hds = flopy.utils.HeadFile(os.path.join(ws, \"sp_mf6.hds\"))\n",
    "final_arr = hds.get_data()\n",
    "fig, ax = plot_model(4, final_arr[4, :, :], units=\"meters\")\n",
    "ax.set_title(\"layer 5 final heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ecccd0-c598-4edf-ba9d-6adc7b89d50e",
   "metadata": {},
   "source": [
    "Ah so nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78b9a6-d538-4671-a178-347351f620ab",
   "metadata": {},
   "source": [
    "The main requirement to use `Mf6Adj` is an input file that describes the performance measures.  Luckily this file has a nice modern format like other MF6 input files.  Here we are going to make one programmatically... `MF6ADJ` supports so-called \"flux-based\" performance measures, which yield the sensitivity of a simulated flux to the model inputs.  This flux-based performance measure can be described very granularly just like the head-based performance measures.  So lets look at the sensitivity of the simulated sw-gw flux between the groundwater system and sfr across all output times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d561207-71b3-4edf-956c-0f0166f06fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_fname = \"sfr_perfmeas.dat\"\n",
    "with open(os.path.join(ws, pm_fname), \"w\") as fpm:\n",
    "    sfr_data = pd.DataFrame.from_records(m.sfr.packagedata.array)\n",
    "    fpm.write(\"begin performance_measure swgw\\n\")\n",
    "    for kper in range(sim.tdis.nper.data):\n",
    "        for kij in sfr_data.cellid.values:\n",
    "            fpm.write(\n",
    "                \"{0} 1 {1} {2} {3} sfr-1 direct 1.0 -1.0e+30\\n\".format(\n",
    "                    kper + 1, kij[0] + 1, kij[1] + 1, kij[2] + 1\n",
    "                )\n",
    "            )\n",
    "    fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe81a8-3f6f-4ac2-a1a0-d4a7602043cb",
   "metadata": {},
   "source": [
    "Ok, now we should be ready to go...the adjoint solution process requires running the model forward once and then solving for the adjoint state, which uses the forward solution components (i.e. the conductance matrix, the RHS, heads, saturation,etc). The adjoint state solution has two important characteristics:  its a linear (independent of the forward model's linearity) and it solves backward in time, starting with the last stress period - WAT?!\n",
    "\n",
    "The adjoint solve is considerably slower than the forward solution, with most of the time being spent in the numpy sparse linear solve...#lyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100b9e4-ff20-4e7c-9875-74db56e6b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = os.getcwd()\n",
    "os.chdir(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248b17e-a17e-488d-9452-a47a3f12bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_hdf5_name = \"forward.hdf5\"\n",
    "start = datetime.now()\n",
    "\n",
    "adj = mf6adj.Mf6Adj(pm_fname, lib_name, logging_level=\"INFO\")\n",
    "adj.solve_gwf(hdf5_name=forward_hdf5_name)  # solve the standard forward solution\n",
    "dfsum = adj.solve_adjoint()  # solve the adjoint state for each performance measure\n",
    "adj.finalize()  # release components\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "print(\"took:\", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f82e2-b6ca-4773-8938-ebc64cc28daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9491c-5c06-4a29-8615-8c1cf4c5870e",
   "metadata": {},
   "source": [
    "Boo ya!  done...let's see what happened..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e43acc-beb5-4f21-84b6-8fa015755c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(ws) if f.endswith(\"hdf5\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fef23f-95fe-406a-bd0e-37391071b2b9",
   "metadata": {},
   "source": [
    "`MF6ADJ` uses the widely available HDF5 format to store information - these files hold very low-level granular information about the adjoint solution.  However the `mf6adj.solve_adjoint()` method also returns a higher-level summary of the adjoint solution.  Let's look at it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d0400-1a2f-4724-982f-f81e3d4697b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62032b-40d3-4836-9117-102eefbcd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfsum.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862cb1a-9b93-4235-8239-649981a5de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhw = dfsum[\"swgw\"]\n",
    "dfhw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80caf3-ef6b-4f3e-b569-46509288723e",
   "metadata": {},
   "source": [
    "those are the node-scale sensitivities to the sfr flux-based performance measure - some plots would be nice you say?!  Well this is most easily done with the HDF5 file itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87353d4e-6e7a-4d8a-b5f2-1e25a44c6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_swgw_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "keys.sort()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9e2d5-da2c-466b-80c2-9503605217a8",
   "metadata": {},
   "source": [
    "The \"composite\" group has the sensitivities of the performance measure to the model inputs summed across all adjoint solutions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa8507-4107-4e3c-a8e8-875a37c0fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [\n",
    "    i for i in grp.keys() if len(grp[i].shape) == 3 and (\"k33\" in i or \"wel\" in i)\n",
    "]\n",
    "plot_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0e3a2-40f0-4d53-a6f9-84f7c25bf601",
   "metadata": {},
   "source": [
    "A simple routine to plot all these sensitivities...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344ad2b-9a3c-4450-a8d1-511cfa909da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(k, karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fec64e-c54e-4bb6-ba77-910dcc8d61e1",
   "metadata": {},
   "source": [
    "There is one plot in there that is particularly well known with the practice of mapping so-called \"capture fraction\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4aaf3-a488-41b0-8650-e92bcc9bdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = grp[\"wel6_q\"][3, :, :]\n",
    "arr[arr == 0.0] = np.nan\n",
    "fig, ax = plot_model(3, np.abs(arr))\n",
    "ax.set_title(\"capture fraction layer 4\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6587c-a8b6-43b7-a7f3-84d0cfa6e065",
   "metadata": {},
   "source": [
    "What is being shown is the capture fraction: the proportion of groundwater \"captured\" from the simulated sw-gw flux if a groundwater well was to be added in a given model cell.  Normally, this would be calculated by mechanically adding a wel/specified flux boundary in each model cell, the running the model with this additional boundary cell, and recording how the sw-gw flux changed, and normalizing this change by the rate used in the added boundary cell, repeat for all active cells! - this can take long time to complete.  However, through the magic of the adjoint, the so-called \"adjoint state\" for this performance measure is simply negative of the capture fraction:  how the simulated gw-sw flux changes as a result of a unit injection of water in each active model cell..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
