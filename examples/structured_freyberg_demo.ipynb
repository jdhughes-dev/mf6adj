{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc90795-fda6-4444-9ee3-94092d2d548e",
   "metadata": {},
   "source": [
    "# Simple `MF6ADJ` demonstration\n",
    "\n",
    "In this notebook, we will quickly run through some standard usage of `MF6ADJ` to calculate sensitivities to a few different performance measures.  We will of course be using the Freyberg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c76ad2-37c7-43eb-9e9e-8bee668d15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib as pl\n",
    "import platform\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import flopy\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151b469-6414-45d7-b238-4a04909263d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import mf6adj\n",
    "except ImportError:\n",
    "    sys.path.insert(0, str(pl.Path(\"../\").resolve()))\n",
    "    import mf6adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701eb24-0fbd-4cb6-b12f-b4dc8bf18908",
   "metadata": {},
   "source": [
    "First we need to get the platform-specific binaries.  We have some strict control over these and they are stored at the root level in the repo in the `bin` dir.  Let's workout what path we should be using and the binary names we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec0fa0-67d7-4910-91e5-8ef911207cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = pl.Path(os.environ.get(\"CONDA_PREFIX\", None))\n",
    "assert env_path is not None, \"Notebook must be run from the mf6adj Conda environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765da9ff-6d29-40d2-8f60-328695778ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = \"bin\"\n",
    "exe_ext = \"\"\n",
    "if \"linux\" in platform.platform().lower():\n",
    "    lib_ext = \".so\"\n",
    "elif \"darwin\" in platform.platform().lower() or \"macos\" in platform.platform().lower():\n",
    "    lib_ext = \".dylib\"\n",
    "else:\n",
    "    bin_path = \"Scripts\"\n",
    "    lib_ext = \".dll\"\n",
    "    exe_ext = \".exe\"\n",
    "lib_name = env_path / f\"{bin_path}/libmf6{lib_ext}\"\n",
    "mf6_bin = env_path / f\"{bin_path}/mf6{exe_ext}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293ef70-a3df-4517-b4f8-a8358ae21b1e",
   "metadata": {},
   "source": [
    "Now let's get the model files we will be using - they are stored in the autotest directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0ce01-6a15-4a0c-bbd2-edf24bb9bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ws = os.path.join(\"..\", \"autotest\", \"freyberg_structured\")\n",
    "assert os.path.exists(org_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c71ba8-e762-4df4-9f42-a2997cabf705",
   "metadata": {},
   "source": [
    "setup a local copy of the model files.  Also copy in the binaries we need for later...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb91bb-a8dd-4d32-bb27-953e58eb6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = \"freyberg\"\n",
    "if os.path.exists(ws):\n",
    "    shutil.rmtree(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b72d6e-7eeb-4343-b6d8-65d8feb5b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree(org_ws, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa4041-7c0c-431b-81d8-20f7632fb6d1",
   "metadata": {},
   "source": [
    "shutil.copytree(os.path.join('..','autotest','xmipy'), os.path.join(ws, 'xmipy'))\n",
    "shutil.copytree(os.path.join('..','autotest','bmipy'), os.path.join(ws, 'bmipy'))\n",
    "shutil.copytree(os.path.join('..','autotest','modflowapi'), os.path.join(ws, 'modflowapi'))\n",
    "shutil.copytree(os.path.join('..','autotest','flopy'), os.path.join(ws, 'flopy'))\n",
    "shutil.copytree(os.path.join('..','mf6adj'), os.path.join(ws,\"mf6adj\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62fe87-0221-43bd-be74-20c59d0b1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=ws)\n",
    "m = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34002a57-43da-4557-b46c-97ce1849fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = m.dis.idomain.array[0, :, :].astype(float)\n",
    "ib[ib > 0] = np.nan\n",
    "ib_cmap = plt.get_cmap(\"Greys_r\")\n",
    "ib_cmap.set_bad(alpha=0.0)\n",
    "\n",
    "\n",
    "def plot_model(arr, units=None):\n",
    "    arr[~np.isnan(ib)] = np.nan\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    cb = ax.imshow(arr, cmap=\"plasma\")\n",
    "    plt.colorbar(cb, ax=ax, label=units)\n",
    "    plt.imshow(ib, cmap=ib_cmap)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418ecbd-a885-4da6-9cad-a503aa360e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_model(m.dis.top.array[:, :])\n",
    "_ = ax.set_title(\"top\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7d4ff-7ddb-426d-ad7b-5f5c63ac29b1",
   "metadata": {},
   "source": [
    "Run the existing model in our local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336aa2a-512c-4f5a-81e5-92f34f8be356",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(mf6_bin.name, cwd=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de008c-d873-47a0-8983-7747c65fe231",
   "metadata": {},
   "source": [
    "Now plot some heads..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d391c-75e5-40c6-91c5-8eed664fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hds = flopy.utils.HeadFile(os.path.join(ws, \"freyberg6_freyberg.hds\"))\n",
    "final_arr = hds.get_data()\n",
    "fig, ax = plot_model(final_arr[0, :, :], units=\"meters\")\n",
    "ax.set_title(\"layer 1 final heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ecccd0-c598-4edf-ba9d-6adc7b89d50e",
   "metadata": {},
   "source": [
    "Ah so nice!  see the sfr \"network\" running north-south in the 15th column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78b9a6-d538-4671-a178-347351f620ab",
   "metadata": {},
   "source": [
    "The main requirement to use `Mf6Adj` is an input file that describes the performance measures.  Luckily this file has a nice modern format like other MF6 input files.  Here we are going to make one programmatically and also, while doing so, describe the various performance measure formats that are supported..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b66d9-db81-4625-9134-82164798a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_fname = \"freyberg_perfmeas.dat\"\n",
    "fpm = open(os.path.join(ws, pm_fname), \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4510a-59dd-468c-84cf-9079f6b798da",
   "metadata": {},
   "source": [
    "The simplest type of performance measure is a single simulated head at one place for one simulation time.  Lets make one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3c37c-bca7-408d-ae4c-9e352a832599",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, row, col = 1, 5, 5  # the layer row and column\n",
    "sp, ts = 24, 1  # stress period and time step\n",
    "pm_name = \"pm_single\"\n",
    "fpm.write(\"begin performance_measure {0}\\n\".format(pm_name))\n",
    "fpm.write(\"{0} {1} {2} {3} {4} head direct 1.0 -1e30\\n\".format(sp, ts, layer, row, col))\n",
    "fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42ef55-85d8-4f3e-820a-359cd9df34b6",
   "metadata": {},
   "source": [
    "That's it!  we did it.  The complicated line in the \"performance measure record\" that tells `MF6ADJ` the spatial and temporal information it needs and also tells it about the type of performance measure (\"head\") and also what form of performance measure we want (\"direct\" or \"residual\").  The final two entries are the \"weight\" and the observed value (which is not used for \"direct\" form performance measures but must be supplied with any valid floating point value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f7309-c4ea-4470-8fd0-bd6020602504",
   "metadata": {},
   "source": [
    "Now lets make a more complex \"direct\" form performance measure - using the same l-r-c but across all simulation times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8fa59f-2a37-476e-8ff4-b8fff63c687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer, row, col = 1, 5, 5  # the layer row and column\n",
    "pm_name = \"pm_single_alltimes\"\n",
    "fpm.write(\"begin performance_measure {0}\\n\".format(pm_name))\n",
    "for kper in range(sim.tdis.nper.data):\n",
    "    fpm.write(\n",
    "        \"{0} {1} {2} {3} {4} head direct 1.0 -1e30\\n\".format(\n",
    "            kper + 1, ts, layer, row, col\n",
    "        )\n",
    "    )\n",
    "fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d57f65-bd91-4d98-aeb2-944905a429e9",
   "metadata": {},
   "source": [
    "Boom!\n",
    "\n",
    "Now lets kick it up a notch and make a \"residual\" form performance measure, which is a sum-of-squared weighted residual performance measure...to use the form, we need \"observed values\" so lets just make some noisey simulated values.  Let's use all the l-r-c locations in the MF6 head obs package.  Im sure you can get these from flopy somehow, but I've never been smart enough to figure that out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73218e-048a-4f39-8af7-b854d670f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcs = []\n",
    "k_dict = {}\n",
    "with open(os.path.join(ws, \"head.obs\"), \"r\") as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        if line.strip().lower().startswith(\"end\"):\n",
    "            break\n",
    "        raw = line.strip().split()\n",
    "        lrcs.append(\" \".join(raw[2:]))\n",
    "        k = int(raw[2]) - 1\n",
    "        i = int(raw[3]) - 1\n",
    "        j = int(raw[4]) - 1\n",
    "        if k not in k_dict:\n",
    "            k_dict[k] = []\n",
    "        k_dict[k].append([i, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77984cc1-543b-4efb-9ea2-7495ec30e829",
   "metadata": {},
   "source": [
    "Make some fake observations by adding noise the simulated values - we notionally would only have measured heads from the past so lets just have \"observations\" for the first 11 stress periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91215f8d-49b0-4168-9692-4e33470e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11111)\n",
    "hist_nper = 11\n",
    "obs_vals = {}\n",
    "for lrc in lrcs:\n",
    "    kij = [int(i) - 1 for i in lrc.split()]\n",
    "    vals = final_arr[kij[0], kij[1], kij[2]] + np.random.normal(0, 1, hist_nper)\n",
    "    obs_vals[lrc] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321407f-772d-4494-beda-3674cf1c7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_name = \"pm_ssr\"\n",
    "fpm.write(\"begin performance_measure {0}\\n\".format(pm_name))\n",
    "for kper in range(hist_nper):\n",
    "    for lrc in lrcs:\n",
    "        fpm.write(\n",
    "            \"{0} {1} {2} head residual 1.0 {3}\\n\".format(\n",
    "                kper + 1, ts, lrc, obs_vals[lrc][kper]\n",
    "            )\n",
    "        )\n",
    "fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5fe29-37b3-4cdc-be6d-6e3619e007c3",
   "metadata": {},
   "source": [
    "And now for something really exciting!  `MF6ADJ` also support so-called \"flux-based\" performance measures, which yield the sensitivity of a simulated flux to the model inputs.  This flux-based performance measure can be described very granularly just like the head-based performance measures.  So lets look at the sensitivity of the simulated sw-gw flux between the groundwater system and sfr during the 23rd stress period (which is a dry time) - this would notionally be a prediction focused performance measure...we will use the two `boundname` groupings in the sfr inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d561207-71b3-4edf-956c-0f0166f06fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_data = pd.DataFrame.from_records(m.sfr.packagedata.array)\n",
    "bnames = sfr_data.boundname.unique()\n",
    "bnames.sort()\n",
    "sp = 23\n",
    "for bname in bnames:\n",
    "    bdf = sfr_data.loc[sfr_data.boundname == bname, :].copy()\n",
    "    fpm.write(\"begin performance_measure {0}\\n\".format(bname))\n",
    "    for kij in bdf.cellid.values:\n",
    "        fpm.write(\n",
    "            \"{0} 1 {1} {2} {3} sfr_1 direct 1.0 -1.0e+30\\n\".format(\n",
    "                23, kij[0] + 1, kij[1] + 1, kij[2] + 1\n",
    "            )\n",
    "        )\n",
    "    fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8cb70e-5608-4182-9bf2-09fadfbe249f",
   "metadata": {},
   "source": [
    "Now we snuck in something new there: see that `sfr_1` on the record line? that is the name of the boundary package in the MF6 GWF name file.  `MF6ADJ` also support WEL, GHB, RIV, and CHD for flux based performance measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b77adc-f1d7-477b-86d2-cfa6d3fdf802",
   "metadata": {},
   "source": [
    "Now for a performance measure combining the historical groundwater level measures and the predictive sw-gw exchange flux #winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e007a0e-c519-446d-b49f-a6855f362b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_name = \"pm_combo\"\n",
    "fpm.write(\"begin performance_measure {0}\\n\".format(pm_name))\n",
    "for kper in range(hist_nper):\n",
    "    for lrc in lrcs:\n",
    "        fpm.write(\"{0} {1} {2} head direct 1.0 -1.0e30\\n\".format(kper + 1, ts, lrc))\n",
    "for bname in bnames:\n",
    "    bdf = sfr_data.loc[sfr_data.boundname == bname, :].copy()\n",
    "    for kij in bdf.cellid.values:\n",
    "        fpm.write(\n",
    "            \"{0} 1 {1} {2} {3} sfr_1 direct 1 -1.0e+30\\n\".format(\n",
    "                23, kij[0] + 1, kij[1] + 1, kij[2] + 1\n",
    "            )\n",
    "        )\n",
    "fpm.write(\"end performance_measure\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7939f-6f8f-40c7-9f15-878858a13243",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe81a8-3f6f-4ac2-a1a0-d4a7602043cb",
   "metadata": {},
   "source": [
    "Ok, now we should be ready to go...the adjoint solution process requires running the model forward once and then solving for the adjoint state, which uses the forward solution components (i.e. the conductance matrix, the RHS, heads, saturation,etc). The adjoint state solution has two important characteristics:  its a linear (independent of the forward model's linearity) and it solves backward in time, starting with the last stress period - WAT?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100b9e4-ff20-4e7c-9875-74db56e6b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = os.getcwd()\n",
    "os.chdir(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248b17e-a17e-488d-9452-a47a3f12bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_hdf5_name = \"forward.hdf5\"\n",
    "start = datetime.now()\n",
    "\n",
    "adj = mf6adj.Mf6Adj(pm_fname, str(lib_name), logging_level="INFO")\n",
    "adj.solve_gwf(hdf5_name=forward_hdf5_name)  # solve the standard forward solution\n",
    "dfsum = adj.solve_adjoint()  # solve the adjoint state for each performance measure\n",
    "adj.finalize()  # release components\n",
    "duration = (datetime.now() - start).total_seconds()\n",
    "print(\"took:\", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f82e2-b6ca-4773-8938-ebc64cc28daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9491c-5c06-4a29-8615-8c1cf4c5870e",
   "metadata": {},
   "source": [
    "Boo ya!  done...let's see what happened..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e43acc-beb5-4f21-84b6-8fa015755c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(ws) if f.endswith(\"hdf5\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fef23f-95fe-406a-bd0e-37391071b2b9",
   "metadata": {},
   "source": [
    "`MF6ADJ` uses the widely available HDF5 format to store information - these files hold very low-level granular information about the adjoint solution.  However the `mf6adj.solve_adjoint()` method also returns a higher-level summary of the adjoint solution.  Let's look at it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d0400-1a2f-4724-982f-f81e3d4697b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62032b-40d3-4836-9117-102eefbcd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfsum.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862cb1a-9b93-4235-8239-649981a5de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhw = dfsum[\"tailwater\"]\n",
    "dfhw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80caf3-ef6b-4f3e-b569-46509288723e",
   "metadata": {},
   "source": [
    "those are the node-scale sensitivities to the sfr flux-based performance measure - some plots would be nice you say?!  Well this is most easily done with the HDF5 file itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87353d4e-6e7a-4d8a-b5f2-1e25a44c6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_headwater_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "keys.sort()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9e2d5-da2c-466b-80c2-9503605217a8",
   "metadata": {},
   "source": [
    "The \"composite\" group has the sensitivities of the performance measure to the model inputs summed across all adjoint solutions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa8507-4107-4e3c-a8e8-875a37c0fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [i for i in grp.keys() if len(grp[i].shape) == 3]\n",
    "plot_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0e3a2-40f0-4d53-a6f9-84f7c25bf601",
   "metadata": {},
   "source": [
    "A simple routine to plot all these sensitivities...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344ad2b-9a3c-4450-a8d1-511cfa909da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fec64e-c54e-4bb6-ba77-910dcc8d61e1",
   "metadata": {},
   "source": [
    "what sorcery is this?! How can we have the sensitivity to WEL type boundaries in every model cell when there are only a handful of WEL type boundaries?  And what's the redic business about recharge in layers 2 and 3?!  Well! The adjoint state that we solve for is actually the sensitivity of the performance measure to a unit injection of water in every active model cell - that's just a WEL type boundary sensitivity.  And recharge is the same quantity scaled by cell area.  How cool is that?! Effectively, those \"wel6_q\" plots are capture fraction maps for the headwater sfr reaches.  And that only took a few seconds to calculate!  Boo ya!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e0fc50-fb01-4df9-b322-cc60e17a045f",
   "metadata": {},
   "source": [
    "We can do similar plots for the other performance measures.  Here are the sensitivities to the single head performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4dc59d-291f-4c2e-af3a-57b86a23ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_pm_single_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [i for i in grp.keys() if len(grp[i].shape) == 3]\n",
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac7b62-777a-4426-b394-e02731fe2b85",
   "metadata": {},
   "source": [
    "And here's the sensitivities for the sum-of-squared-weighted residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc90e87-0d53-4736-8645-2c02af9409c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_pm_ssr_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [i for i in grp.keys() if len(grp[i].shape) == 3]\n",
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118821d-c425-4870-b44d-c2e49d14ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hdf = \"adjoint_solution_pm_combo_forward.hdf5\"\n",
    "hdf = h5py.File(os.path.join(ws, result_hdf), \"r\")\n",
    "keys = list(hdf.keys())\n",
    "grp = hdf[\"composite\"]\n",
    "plot_keys = [i for i in grp.keys() if len(grp[i].shape) == 3]\n",
    "for pkey in plot_keys:\n",
    "    arr = grp[pkey][:]\n",
    "    for k, karr in enumerate(arr):\n",
    "        karr[karr == 0.0] = np.nan\n",
    "        fig, ax = plot_model(karr)\n",
    "        ax.set_title(pkey + \", layer:{0}\".format(k + 1), loc=\"left\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
